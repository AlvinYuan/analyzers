{
 "metadata": {
  "name": "",
  "signature": "sha256:1d961585ca2ffe3eaa69e0b2abfcf51d4cee7509252c1d2a80b36ea7962f03f6"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from ggplot import *\n",
      "import datetime\n",
      "import time\n",
      "import urllib\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from pandas import read_csv\n",
      "from pprint import pprint\n",
      "from datetime import timedelta"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 173
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Reads all year.catalog.csv files in github repo.\n",
      "Loads it all into one DataFrame.\n",
      "Does not remove null values, but data seems clean in this sense already.\n",
      "XXX: Note that the row index number appears multiple times. Use iloc and related instead of loc?\n",
      "\"\"\"\n",
      "def load_data(YEAR_MIN=1932, YEAR_MAX=2013):\n",
      "    FILE_DIR = \"../data_from_curators/\"\n",
      "    df = pd.DataFrame()\n",
      "    for yr in range(YEAR_MIN, YEAR_MAX+1):\n",
      "        filepath = FILE_DIR + \"%d.catalog.csv\" % yr\n",
      "        df = df.append(pd.read_csv(filepath))\n",
      "    # Convert time fields to a datetime object\n",
      "    df[\"datetime\"] = pd.to_datetime(df.apply(lambda row: row[\"YYYY/MM/DD\"] + \" \" + row[\"HH:mm:SS.ss\"], axis=1))\n",
      "    return df\n",
      "\n",
      "# May take ~ 1 minute\n",
      "full_data = load_data(2013, 2013)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 174
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Some sanity checks\n",
      "\"\"\"\n",
      "print full_data.info()\n",
      "print full_data[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 16091 entries, 0 to 16090\n",
        "Data columns (total 13 columns):\n",
        "YYYY/MM/DD     16091 non-null object\n",
        "HH:mm:SS.ss    16091 non-null object\n",
        "ET             16091 non-null object\n",
        "MAG            16091 non-null float64\n",
        "M              16091 non-null object\n",
        "LAT            16091 non-null float64\n",
        "LON            16091 non-null float64\n",
        "DEPTH          16091 non-null float64\n",
        "Q              16091 non-null object\n",
        "EVID           16091 non-null float64\n",
        "NPH            16091 non-null float64\n",
        "NGRM           16091 non-null float64\n",
        "datetime       16091 non-null datetime64[ns]\n",
        "dtypes: datetime64[ns](1), float64(7), object(5)None\n",
        "   YYYY/MM/DD  HH:mm:SS.ss  ET   MAG  M     LAT      LON  DEPTH  Q      EVID  \\\n",
        "0  2013/01/01  00:55:30.86  le  0.75  l  33.973 -116.807   13.9  A  15269305   \n",
        "1  2013/01/01  01:22:48.22  le  1.61  l  34.909 -119.596   10.0  A  15269313   \n",
        "2  2013/01/01  01:30:15.24  le  0.28  l  35.946 -117.662    5.0  A  15269321   \n",
        "3  2013/01/01  01:50:54.74  le  0.64  l  33.704 -116.751   19.5  A  15269329   \n",
        "4  2013/01/01  02:00:11.27  le  0.83  l  33.276 -116.780   13.0  A  15269337   \n",
        "5  2013/01/01  02:47:58.48  le  1.87  l  33.782 -118.358    8.2  A  15269353   \n",
        "6  2013/01/01  03:01:55.10  le  1.13  l  34.177 -117.364   12.8  A  15269361   \n",
        "7  2013/01/01  03:29:39.68  le  1.66  l  36.155 -118.064    0.5  A  15269369   \n",
        "8  2013/01/01  06:10:05.13  le  1.01  l  36.151 -118.073    5.6  C  15269377   \n",
        "9  2013/01/01  06:36:26.07  le  0.67  l  33.658 -116.733   15.7  A  15269385   \n",
        "\n",
        "   NPH  NGRM                   datetime  \n",
        "0   32     0 2013-01-01 00:55:30.860000  \n",
        "1   27     0 2013-01-01 01:22:48.220000  \n",
        "2    9     0 2013-01-01 01:30:15.240000  \n",
        "3   18     0 2013-01-01 01:50:54.740000  \n",
        "4   36     0 2013-01-01 02:00:11.270000  \n",
        "5   59     0 2013-01-01 02:47:58.480000  \n",
        "6   54     0 2013-01-01 03:01:55.100000  \n",
        "7   38     0 2013-01-01 03:29:39.680000  \n",
        "8   14     0 2013-01-01 06:10:05.130000  \n",
        "9   38     0 2013-01-01 06:36:26.070000  \n"
       ]
      }
     ],
     "prompt_number": 175
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Split data into training, validation, and test sets.\n",
      "Splits based on order: training is earliest data, validation is middle, test is latest.\n",
      "Cannot split randomly because we believe there is time clustering.\n",
      "This may introduce confounds with quality of data though (is earlier data more reliable?).\n",
      "For now, assume data quality is constant across time.\n",
      "\"\"\"\n",
      "def split_data(data, training_size, validation_size, test_size):\n",
      "    assert(training_size + validation_size + test_size == 1)\n",
      "    validation_start = int(len(data) * training_size)\n",
      "    test_start = int(len(data) * (training_size + validation_size))\n",
      "    return (data[:validation_start], data[validation_start:test_start], data[test_start:])\n",
      "\n",
      "training, validation, test = split_data(full_data, .6, .2, .2)\n",
      "assert(len(training) + len(validation) + len(test) == len(full_data))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 176
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Convert data to matrix\n",
      "\"\"\"\n",
      "event_times = np.matrix(training[\"datetime\"].values).getT()\n",
      "event_magnitudes = np.matrix(training[\"MAG\"].values).getT()\n",
      "num_events = event_times.shape[0]\n",
      "print num_events"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "9654\n"
       ]
      }
     ],
     "prompt_number": 177
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def mda(event_times, event_magnitudes, tau=700, u=4):\n",
      "    \"\"\"\n",
      "    Uses basic MDA model (tau*u^mag) to predict earthquakes.\n",
      "    Returns matrix of (start, end) representing date range when alarm should be on.\n",
      "    \"\"\"\n",
      "    num_events = event_times.shape[0]\n",
      "    start_offset = np.timedelta64(1, \"ms\")\n",
      "    event_times2 = np.repeat(event_times, 2, axis=1)\n",
      "    start_offsets = start_offset * np.ones([num_events, 1])\n",
      "\n",
      "    # MDA\n",
      "    stop_offsets = np.timedelta64(1, \"ms\") * np.floor( tau * np.power(u, event_magnitudes) )\n",
      "\n",
      "    offsets = np.concatenate((np.mat(start_offsets), np.mat(stop_offsets)), axis=1)\n",
      "    alarms = event_times2 + offsets\n",
      "    \n",
      "    \"\"\"\n",
      "    Clean alarm data so that alarms do not overlap.\n",
      "    Clean alarm data so that whether an event was predicted can be checked by the alarm range in the same row\n",
      "    TODO: can this be done as a matrix operation\n",
      "    \"\"\"\n",
      "    cutoff_offset = - 2 * start_offset\n",
      "    for i in range(1, alarms.shape[0]):\n",
      "        previous_alarm_end = alarms[i-1, 1]\n",
      "        if alarms[i, 0] < previous_alarm_end:\n",
      "            # latest alarm after this event\n",
      "            # This event is predicted\n",
      "            # There is an overlap in alarm ranges\n",
      "            cutoff = alarms[i, 0] + cutoff_offset # result should be before event i timestamp\n",
      "            # Start alarm for event i before event i to indicate predicted\n",
      "            alarms[i, 0] = cutoff\n",
      "            # Update alarms to not overlap\n",
      "            alarms[i-1, 1] = cutoff\n",
      "            # Update latest alarm\n",
      "            if alarms[i, 1] < previous_alarm_end:\n",
      "                alarms[i, 1] = previous_alarm_end\n",
      "        # else:\n",
      "        # latest alarm ends before this event\n",
      "        # No overlap, no update\n",
      "\n",
      "    # cutoff final alarm so it does not contribute to alarm_fraction\n",
      "    alarms[-1, 1] = alarms[-1, 0] + cutoff_offset\n",
      "    return alarms"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 178
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def automatic_alarm(event_times, alarm_length=1000):\n",
      "    \"\"\"\n",
      "    Uses basic automatic alarm to predict earthquakes.\n",
      "    Returns matrix of (start, end) representing date range when alarm should be on.\n",
      "    \"\"\"\n",
      "    num_events = event_times.shape[0]\n",
      "    start_offset = np.timedelta64(1, \"ms\")\n",
      "    event_times2 = np.repeat(event_times, 2, axis=1)\n",
      "    start_offsets = start_offset * np.ones([num_events, 1])\n",
      "\n",
      "    # Automatic alarm\n",
      "    stop_offsets = np.timedelta64(alarm_length, \"ms\") * np.ones([num_events, 1])\n",
      "\n",
      "    offsets = np.concatenate((np.mat(start_offsets), np.mat(stop_offsets)), axis=1)\n",
      "    alarms = event_times2 + offsets\n",
      "\n",
      "    \"\"\"\n",
      "    Copied from mda\n",
      "\n",
      "    Clean alarm data so that alarms do not overlap.\n",
      "    Clean alarm data so that whether an event was predicted can be checked by the alarm range in the same row\n",
      "    TODO: can this be done as a matrix operation\n",
      "    \"\"\"\n",
      "    cutoff_offset = - 2 * start_offset\n",
      "    for i in range(1, alarms.shape[0]):\n",
      "        previous_alarm_end = alarms[i-1, 1]\n",
      "        if alarms[i, 0] < previous_alarm_end:\n",
      "            # latest alarm after this event\n",
      "            # This event is predicted\n",
      "            # There is an overlap in alarm ranges\n",
      "            cutoff = alarms[i, 0] + cutoff_offset # result should be before event i timestamp\n",
      "            # Start alarm for event i before event i to indicate predicted\n",
      "            alarms[i, 0] = cutoff\n",
      "            # Update alarms to not overlap\n",
      "            alarms[i-1, 1] = cutoff\n",
      "            # Update latest alarm\n",
      "            if alarms[i, 1] < previous_alarm_end:\n",
      "                alarms[i, 1] = previous_alarm_end\n",
      "        # else:\n",
      "        # latest alarm ends before this event\n",
      "        # No overlap, no update\n",
      "\n",
      "    # cutoff final alarm so it does not contribute to alarm_fraction\n",
      "    alarms[-1, 1] = alarms[-1, 0] + cutoff_offset\n",
      "    return alarms"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 179
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "alarms = mda(event_times, event_magnitudes)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 72.9 ms, sys: 0 ns, total: 72.9 ms\n",
        "Wall time: 248 ms\n"
       ]
      }
     ],
     "prompt_number": 180
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time \n",
      "\"\"\"\n",
      "Returns the fraction of time the alarm is on.\n",
      "Assumes arguments are sorted by time and alarms do not overlap.\n",
      "\"\"\"\n",
      "def alarm_fraction(event_times, alarms):\n",
      "    time_frame = event_times[-1,0] - event_times[0, 0]\n",
      "    alarm_time = np.sum(alarms[:,1] - alarms[:,0])\n",
      "#     print time_frame / np.timedelta64(1,\"D\"), alarm_time / np.timedelta64(1,\"D\")\n",
      "    return alarm_time / time_frame\n",
      "\n",
      "print alarm_fraction(event_times, alarms)\n",
      "\n",
      "# print event_times[0,0]\n",
      "# print event_times[-1,0]\n",
      "# print (validation[\"datetime\"].values[-1] - validation[\"datetime\"].values[0])\n",
      "# print (validation.iloc[-1][\"datetime\"] - validation.iloc[0][\"datetime\"]).total_seconds()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.00290736288229\n",
        "CPU times: user 256 \u00b5s, sys: 2 \u00b5s, total: 258 \u00b5s\n",
        "Wall time: 262 \u00b5s\n"
       ]
      }
     ],
     "prompt_number": 181
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\"\"\"\n",
      "Returns the number of correct predictions.\n",
      "Assumes alarm for event i starts before event i if a previous alarm predicted event i.\n",
      "\"\"\"\n",
      "def prediction_positives(event_times, alarms):\n",
      "    num_events = event_times.shape[1]\n",
      "    deltas = event_times > alarms[:,0]\n",
      "    return np.sum(deltas)\n",
      "\n",
      "def error_ratio(event_times, alarms):\n",
      "    num_events = event_times.shape[0]\n",
      "    return (num_events - prediction_positives(event_times, alarms)) / float(num_events)\n",
      "print prediction_positives(event_times, alarms), error_ratio(event_times, alarms)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "98 0.98984876735\n",
        "CPU times: user 323 \u00b5s, sys: 0 ns, total: 323 \u00b5s\n",
        "Wall time: 324 \u00b5s\n"
       ]
      }
     ],
     "prompt_number": 182
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\"\"\"\n",
      "Compute alarm_fractions and error_ratios for mda by varying tau\n",
      "\"\"\"\n",
      "mda_taus = [1000 * 2**i for i in range(14)]\n",
      "# taus = xrange(1000, 1048000, 10000)\n",
      "mda_alarm_fractions = []\n",
      "mda_error_ratios = []\n",
      "\n",
      "for tau in mda_taus:\n",
      "    mda_alarms = mda(event_times, event_magnitudes, tau)\n",
      "    mda_alarm_fractions.append(alarm_fraction(event_times, mda_alarms))\n",
      "    mda_error_ratios.append(error_ratio(event_times, mda_alarms))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 1.86 s, sys: 5.9 ms, total: 1.87 s\n",
        "Wall time: 3.53 s\n"
       ]
      }
     ],
     "prompt_number": 183
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\"\"\"\n",
      "Compute alarm_fractions and error_ratios for automatic alarms by varying alarm_length\n",
      "\"\"\"\n",
      "aa_alarm_lengths = [1000* 2**i for i in range(14)]\n",
      "aa_alarm_fractions = []\n",
      "aa_error_ratios = []\n",
      "\n",
      "for alarm_length in aa_alarm_lengths:\n",
      "    aa_alarms = automatic_alarm(event_times, alarm_length)\n",
      "    aa_alarm_fractions.append(alarm_fraction(event_times, aa_alarms))\n",
      "    aa_error_ratios.append(error_ratio(event_times, aa_alarms))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 1.47 s, sys: 133 \u00b5s, total: 1.47 s\n",
        "Wall time: 1.93 s\n"
       ]
      }
     ],
     "prompt_number": 184
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Plot the commonly used chart\n",
      "Based off HW1 precision vs. recall plot\n",
      "\"\"\"\n",
      "import pylab\n",
      "%matplotlib inline\n",
      "pylab.title(\"Earthquake Model Performance Curves\")\n",
      "pylab.xlabel(\"Alarm Fraction\")\n",
      "pylab.ylabel(\"Error Ratio\")\n",
      "pylab.plot(aa_alarm_fractions, aa_error_ratios,'r--', label=\"AA\")\n",
      "pylab.plot(mda_alarm_fractions, mda_error_ratios, 'b--', label=\"MDA\")\n",
      "pylab.legend()\n",
      "pylab.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEZCAYAAACTsIJzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xd8VFX+//FXErp0siCiiNiQoiBFEMEo6IK6shZAEBRx\nbV8RVywItrgK1p+yLOqy6CKwINhQsIAohKJUCVWKKCggSieUQEIyvz8+d5KbkDIhmbkzk/fz8ZhH\n5s69c+9nbmbu595zzj0HRERERERERERERERERERERERERERERALWAMgEYj3YdhJwpwfbDUQDAt8v\n/YD5wQzGpT3wI3AQuD5E2xQpkBcHj9JuC3AEOxD4HyOLub4rix1VyfA5j+LaAhwDauV6PRk7uNcv\ngW2crAZODP7/3WZgcDHW9w/s/18FmFbc4CJEOSAR2AgcwvbhO8CZHsYkLkoMoecDrsMOBP7HwJNY\nTxnX+mJKJrSw4QN+Bnq5XmsGVKRkEk9JqIb973oBTwN/LuL7/f+/+sAPJxlD3Em+z2sfYr+BXkBV\n4CJgGdDpJNZVpvBFpKiUGMLL2cBsYDewC/gfdgDy2wI8BqzEzrQmYQeW6djZ6yOuZfsAvzjrGep6\nvSLwLrAXWAs8Cmx1zc8EGrqm3wWec57XAD4Ddjrvnw7Uy+ez1AVWAQ87022B74B9wArg8nze5/c/\n4DbX9O3AeHImwWrOazuxffOEa34s8Cr2+X8Crs21/mrYWepvwDbnM57M72ERth+bONP9sQP9XmAG\nOa9uMoH/w86UNwKbsH09HUgBygKnYVcOe7Aipr+53p+IHVQnAAewIq8k4HngW+w7MA2IByY6yywh\n55n4P4FfnXnLgMtyrf99YJwTzxqgpWv+GcDH2P7eDfzLNa+gz+3W2Xl0A7539kkK8BbwX2eZLeRM\nEonOZ4bsK7b+2Pf7G+AL4P5c21kJ/NV53giYhe3T9UB313LXYP+/FOx78DAiHthM/mdGZzvzymI/\n7rnA6675W4Dl2MG4vGt97qKkBtgPZ7SzzIXAUeB8Z/6LznqrA6djP/5fXe/PnRjGYsUdADWBG4AK\nQGXsIDLVtewc7Ad7FrCB7INaPexA0sWZ7uxMx+ezH/z7aD32o47Dkld9chYljXe2fwp28NvgbB/g\nXmCds+0aTmwZZB/8p2IHo4rAn4DFwN3OvH7kX8fQwIkhDktC7YHDwBXYwe5HbF/HYonqW9d7M4GZ\n2L7P7/83DxiFFbdchB2Er3DmJQJpZNdFVMASw0Zsn1fFDnI/OuuMww7y/gMuwK3O/ogFBgE7nG35\n15+K/Z9igOHAQmdeHHaw/X/YPivvfHYC+NxuL2L/i4Lk3ifPcGJieNeJowLQF1jgWr4xdgJSFvtu\nbMVOLGKB5tjJQiNn2R2uz1ENaFFIbCJBsQU7s9vneuRXYftXLBH4bcYOWuR6La/EcJrrtcVAD+f5\nT8DVrnl3UfAVw1iyrxhya46dIfrNwQ4cm4GertcHYwdxtxnkvCJw8yeGJ7CDUxfsgBpHdmKIw+oh\nGrnedzfZB53ZZB/oAa4iu/K5DpYsK7jm93LeA4Elhn3YZ/8BGODM+5LsxISzrcPYmTbO+xLy+Kz+\n/98ZwHHsYOY3HPsfgB24k3K9fw4wxDX9KvC5a/o6rG4mP3uxYjr/+r9yzWuM1YcBtMOSVF5XVYV9\nbrcxwHsFxAMnfqcTOTExNHDNr4JdQfu3Nwx423neE0u2bqOx4j+wq467saQqDhUlhZ4PO8Oq4Xq8\n48yrA0zGLmkPYD+G3BWwWwnM767nR7AzfLCE4V6H+2qhMJWwH9UWJ7652FmWv/gmBjsj3QZ85Hrf\nmdjluzsZtgdOLWBbPuzz30rexUjx2BnhL7k+i79oqy75f84znffucMXzb+zKIVC1sCuoxtgZvn+9\n/3Stc4/zuru4raD/32nYgfpwrrjd79+Wx/v+cD0/ih3A3dOVXdOPYMlsvxNjNXJeubnXdQRLnrHY\nQfcX7KCcWyCf22839r8pLvd+PIglQ3+d1C1YUZo/tkvI+d3rjf3WAG7CipO2YEm3bQnEFvGUGMLL\ncKy4oyn2g+3Lif+j3JWvRa2M3UHO8t/cZcFHsATgV9e1jYeB84A2TnyXYwdr/wHbh13278HqP/yx\n/4od5N3JsArwciGx/opVQnfFyrbddgPp5DxzrE/2gbOgz7mV7FZP/niqkX3mfLJ+xc4+3Z/zFKwe\nwq+g/9dvWLJxH8jdn6mw9xc2vwNWp9QdK86qgSX4QBov+Ivy8qrwDuRz+32NfX/yq5sCS4zuq6a8\nTiByf873sMTQDktm/ivHX7ETmNzfPX+dxDLsyvxPwCdY8Wipp8Tgjfx+iJWxH0UK9sN5NIB1/YHV\nTQTqfazowV/H8AA5f2QrsLP0OKwIp2Ou+FKxg0lNLAnklo4deE4h+yz/f8BfsCKsOOyHm0DBBwe/\nO7FihdRcr2c4n2WYE9eZwEPOtvyfcyDZdQyPu967AysyeQ07SMRi+9D9WU/Gv7GK/sbOdDVyVnQW\nZitWQf8C2fVD/cn+TPmJyed5blWwoqrdWL3C0wRehLIE228vYicOFYBLnXlF+dzfYBXBU4GLsVZF\nVbA6oTucZVZgZ/1lgFbYWX1hCfEL7DvwLHbV7fcZdjLTB7tKLAu0xoogy2Lf9WrY9+mg87fUU2Lw\nhr8Vkf/hL3Z5FvuxHHCW+YjCfxAvAE9il8iDnNcKes+zWJHAZqycP3cRzYPYQdx/ye2uXB6BVfjt\nxg5gX+azrXTgRuxy/R1gO1Z8NhQr5vgVu/oI5Pv3MznrWdzbewBLpD9jdQITyS6PH4PVS6zEzgpz\n78vbsIOjvyXNB2SfmRZ2P0Z+8z4BXsIOTAeA1eRsxhrI1V0v7CroN+wq6Wmy6z7yi8uX63l+V5Uz\nnMdGrOgklZxFbAW9NwP7XpzjvGcr2fVWhX3u3G7GDuRTsCKt1dj3fpYz/yksUe/D6hcm5np/Xvsg\nDdtfnbCrVb9D2AnJLdj3cAf2m/FXuPfBfgsHsKueWwuIW0rIf7Ez2tUFLDMSa9GwErUI8EICgddb\niIgUWwfsYJ9fYrgGO3MAqyDKq0xSgisBJQYRcQl2UdJ87HIwP9dj7azBmlRWJ7u1gIROuNxNLCJh\nwOs6hnrkPFvdhlWISugk4W3fQyISZrxODHBiKwqdvYqIeMjrDqi2k/PuyNOd13I4u0YN30/7CiqR\nEhGRPPyEtSQrEq+vGKaR3S1CW6zp2h+5F/pp3z58q1fj8/lK/eOZZ57xPIZweWhfaF9oXxT8oGj3\nOGUJdmJ4D2vvfj5Wl9AfuMd5gLVI+hnrZXI01vNknqYOXYpPhUwiIkEX7KKkXoUvktUBWYEGf9GR\n+KTjdLjC69IvEZHo5nVRUsD+ftY0Xh+8w+swPJeQkOB1CGFD+yKb9kU27Yvii5SRv3yHPppBg55t\nWLiuBucUuSpFRKT0iYmJgZM4zkdMYvBlZvLEoFT2p1XijTe8DkdEvFCzZk32qYXiCWrUqMHevXtP\neD36E4PPx++/Q+PGsHEjxOc39peIRK2YmBh/axtxyW+/lIrEALByJTRrBrERUzsiIiVFiSFvpT4x\niEjppcSQt5JODDrvFhGRHCIzMWzdCk8/XfhyIiJSZJGZGP70J3j7batwEBEJMwkJCdSsWZO0tLQT\n5m3evJnY2Fj+7//y7ejBc5GZGCpUgIcf5rXbV/Lzz14HIyKSbcuWLSxZsoTatWszbdq0E+aPHz+e\npk2bMmXKlDwTRziIzMQAcM89HN20jYf67/c6EhGRLOPHj6dz58707duXcePG5Zjn8/mYMGECiYmJ\n1KpVi+nTp3sUZcEiNzFUrszDr5/OukUH+GJ6htfRiIgAlhh69uxJjx49mDlzJjt37syat2DBAv74\n4w+uueYaunfvfkLiCBeRmxiA8n/ry8g2Exl4/3GOHvU6GhEJC4mJEBNz4iMxMfDl81u2EAsWLGD7\n9u1cf/31nHvuuTRu3JhJkyZlzR83bhx/+ctfqFChAt27d2fGjBns2rXrpLYVTFFxH8MNN0DLlvDk\nkyGMSERCLtzvY7jrrrvYuXMnn376KQDDhg3jww8/JDk5mdTUVOrWrcvYsWO54YYbADjvvPO4//77\nefDBB4u1Xd3gloctW+CJJ+B//7NkLyLRKZwTQ2pqKqeeeiqZmZlUrlwZgGPHjnHgwAGSk5NZs2YN\nffr0IT4+nri4OAD279/PBRdcwPLly4u1bSUGESm1wjkxvPfeewwYMICVK1dSrlw5wCqbe/ToQatW\nrVizZg3169dn2LBhWe/Ztm0brVu3ZuXKlTRt2vSkt63EICKlVjgnhq5du9K0aVNeeeWVHK9/8MEH\n3HrrrQAkJyfTpEmTHPOvvfZamjRpwssvv3zS21ZiKEhGBnz1FXTtGvyIRCTkwjkxeEl9JRXk2DF4\n4AH44guvIxERiVjRlRgqVYLRo0m551Hu6Z9GaqrXAYmIRJ7oSgwAnTpR5ep2HJy9lHvv9aGrThGR\noomuOga/1FSOXHY17Xd8QL/Bp1LMJsIiEiZUx5A31TEEomJFKn32PlMvfp4XXvAxe7bXAYmIRI7o\nvGJwmT0beveG5GSoW7eEoxKRkNIVQ97UXPUkLFkCrVppnGiRSKfEkDclBhEptZQY8qY6huLIyEDN\nlERECla6EsOQIfDcc15HISJRqEGDBpQvX549e/bkeL1FixbExsbyyy+/0K9fP8qXL0/VqlWpWrUq\nzZo1Y+jQoaSkpJywvsTERGJjY1myZEmoPkKW0pUYHnoI3n6bLW98znffeR2MiESTmJgYGjZsyHvv\nvZf12urVq0lNTfUX6RATE8PgwYNJSUlh9+7djB07lkWLFtG+fXuOHDmS9T6fz8f48eNp1qwZ48eP\nD/lnKV2JoW5d+PRTNg8dQ7dr05kzx+uARCSa9OnTJ8eBfNy4cdx22205yv/9z8uVK0erVq2YNm0a\ne/bsYezYsVnLzJ8/n5SUFP75z38yefJk0tPTQ/chKG2JAaBFC64YexsflOlNz+4ZfPWV1wGJSLRo\n27YtKSkprF+/noyMDKZMmUKfPn0KfE/lypW56qqrmD9/ftZr48aN44YbbiAhIYGKFSuGfGzo0pcY\nAG68kYSHWjD1ylH06QOff+51QCJSUjwc2ROAvn37Mn78eGbNmkXjxo2pV69eoe+pW7cue/fuBeDI\nkSN8+OGHdO/eHYCbbrop5MVJZUK6tXAyZAjtMzKY/j1cfz3Mmwfnn+91UCJSXImJRTuwF3X5gsTE\nxNC3b186dOjA5s2bTyhGys/27dupVasWAFOnTqVs2bJ06tQJgO7du3PllVeye/du4uPjSybQQpTO\nKwaw04IyZbjkElixQklBREpG/fr1adiwIV9++SU33njjCfP9FdF+hw4d4uuvv6ZDhw6AFSMdPHiQ\n008/nbp163LTTTeRnp7OpEmTQhI/lOYrBhd1lSEiJemdd95h//79VKxYkePHj2e97vP5sq4gjh07\nxpo1axg8eDC1atXijjvuYPv27cyePZsZM2Zw4YUXZr1nxIgRjB8/noEDB4Yk/tJ7xZCXI0d0A5yI\nFFvDhg25+OKLs6bdzVVffvllqlatSnx8PLfffjutW7fmu+++o2LFikyYMIEWLVrQuXNnateuTe3a\ntalTpw4DBw5k9erV/PDDDyGJP9hdYnQBRgBxwNvAS7nmxwP/A07Frl5eBd7NYz2h6RLjoYdg/374\nz384eLQsVaoEf5MiEjh1iZG3SOorKQ7YAHQGtgNLgV7AOtcyiUB5YAiWJDYAdYDj5BSaxHD4MPTo\ngS/Tx+Up07m5ZxwhunITkQAoMeQtkvpKagNsArYA6cBkoFuuZXYAVZ3nVYE9nJgUQueUU+CTT4ip\neyoTDt3AyNczeOUVz6IREfFEMBNDPWCra3qb85rbGKAJ8BuwEvB+rLWyZeGddzjzLxcyl8t5+9/H\nef55r4MSEQmdYLZKCuR6byiwAkgAzgZmARcBB3MvmOhqaJyQkEBCQkIJhJiPmBh4/nnqtf2Muc2h\n05/h2DH1vyci4S0pKYmkpKRiryeYdQxtsTqELs70ECCTnBXQXwDDgG+d6W+AwcCyXOvydDyGXbtg\n+nTo39+zEEQE1THkJ5Iqn8tglcmdsKKiJZxY+fwacAB4Fqt0/h64ENiba10aqEdElBjyUdKJIZhF\nSceBAcBMrIXSO1hSuMeZPxoYDozF6hdigcc4MSmEl9RUqFjR6yhESqUaNWqccOew2H4pSZGyh8Pn\niqFfP6hZE159VYNIi0hYC8fmqtHp9ddh2TJ+6jaIBwccJy3N64BEREqWEkNR1agBM2dSN+Z3tkxZ\nTEKH42zdWvjbREQihRLDyahYkUpTJzL15kl02/oGrVtlMnOm10GJiJQM1TEUh88Hn3zC3Ord6N0n\nlnvvhaee8jooERETjs1VS1J4JgaX33+H776DPLpfFxHxhBKDiIjkoFZJ4eToUa8jEBE5aUoMwXDL\nLfD88+Dz8d13NsSDiEikUGIIhrfego8+gnvvZfrU47RqZeNKi4hEAiWGYKhbF+bOhV27eCGpHcMG\n/sFVV8GYMRo5VETCnyqfg8nng5EjYdgw1k9azs1/P52WLeHNN21MIBGRYFLlcziKiYEHH4QFC2jU\nqR6LF0NcHGzY4HVgIiL50xWDiEiU0hWDiIiUCCUGr2zcCEOGQHo6oCatIhI+lBi8UqsWrF4NHTuy\nad5vNGoEX37pdVAiIkoM3qlVC6ZNgxtv5JzuLfjwoW+5+2548knIyPA6OBEpzVT5HA6+/RZ69WLn\nzf9H71WPk5kJkybBqad6HZiIRDJVPkey9u1h+XJqd76QmTOhQwfo3l03w4mIN3TFEKYOH9ZNcCJS\nPOp2W0REclBRUrSaNQu2b/c6ChEpRZQYwt2qVdCyJcycyZNPWsetungSkWBSUVIkmDMH+vRh4/WP\ncPOCv9PswhhGj4bKlb0OTETCmYqSotkVV8Dy5Zz34+csqt6FcseP0KYN/PCD14GJSDRSYogUderA\nzJlUuvoyxj6+gUcegcsvh6QkrwMTkWijoqQItmoVnH461KzpdSQiEo7UXFVERHJQHUNp5xr9JzPT\nwzhEJOIpMUSDnTshIQGeew4yMujaFV59VZ3xicjJUWKIBrVrw/ffw9dfQ9euvPXcbr74Ai69FNau\n9To4EYk0SgzR4rTT4JtvoHVrGt7YnG+ensudd2ZfSDjjAYmIFEqVz9FoxgwYPhxmz2brjjLcey/c\ndhv07Ol1YCISSmqVJDn5fGBfiqwuNGIi5b8tIiXiZBNDmZIPRcKCKwsoIYhIUQS7jqELsB74ERic\nzzIJQDKwBkgKcjylW1pajrasCxbYuA8iIm7BTAxxwCgsOTQGegEX5FqmOvAG8BegKXBzEOORESPg\nuuuyuvGePBmaNbM6axERv0ATw6nYwfs6oHaA72kDbAK2AOnAZKBbrmV6Ax8B25zp3QGuW07GQw9B\n69bQvDm8+SajRmYyahTccQfcdRccOOB1gCISDgJJDD2AxUB35/kS53lh6gFbXdPbnNfczgVqAnOA\nZUDfANYrJ6tsWXj2Wet5b+JEuOwyrjlzLWvWQFwcNG0Kc+d6HaSIeC2QyucngdbATmf6T8A3wAeF\nvC+QZkRlgYuBTkAlYCGwCKuTkGBp0gTmz4fRo2H0aKqOHMm//23DPsTHex2ciHgtkMQQA+xyTe8h\nsOZP24EzXNNnkF1k5LcVKz5KdR7zgIvIIzEkJiZmPU9ISCAhISGAECRfsbFw3305XrriCo9iEZES\nkZSURFIJ9MUfyAH+FexgPclZviewCniskPeVATZgVwO/YUVQvYB1rmUaYRXUfwbKY0VWPYHcQ9Do\nPgYRkSIKZu+qjwGjseTQzHleWFIAOA4MAGZiB/opWFK4x3mANWWdgSWaxcAYTkwKEmqrVsHHH2dN\nPvAAjBunsaZFSotIufVJVwyhtGwZ9O0LjRrBqFEs/6Me/ftD3bpWLVG/vtcBikgggnHF8K3z9xBw\nMNcjpagbkgjSqhWsWAEXXgjNm3Px4rdYujiTyy6Dli3hrbc05oNINNMVgxRs7Vq4+26oXh0++4wf\n1sXQvz/07g0DB3odnIgUJJid6E3gxPsL8notmJQYvJSZCevWWTNXbACg9HSoUMHjuESkQMFMDMlA\nC9d0GayyuHFRN1YMSgwiIkUUjDqGoVh9QjNy1i/sBKYVPUSJOpmZkJJd3bR5swYEEokGBSWG4UAV\n4FXnr/9RE3g8+KFJ2FuwABo3zmra+sor0KYNJCd7HJeIFEuglxg1sH6N3KXK80o+nHypKClczZtn\nldMXXIDvX6MY/009Hn3UOuV76inVQ4h4KZg3uN2FJYGvgGexG9YSi7ohiVIdO1rT1mbNiGnRnNuP\nvMXK5EzWrYMWLWDxYq8DFJGiCiSTrME60VsINMe6sXgBuCGIceWmK4ZIsHYtjBwJb7yBL64MH34I\nFSvaEBAiEnrBbJW0DGgFrADaAkexbivUKklEJIwFc8znrVgdwyfALGAfNviOiIhEoaJmkgSgKtbx\nXVqJR5M/XTFEsj174IUXrDa6WjVGj4YzzoBrrvE6MJHoFszKZ7ckbGyGT4u6ISnFypSx+x2aNIGp\nUznnHLj/frjtNti71+vgRCS3ghJDB2A1cAQbS6EllhDewLrHFglMtWrwn//YcKKPP06nN25k9Vc7\nqFHDhhP96COvAxQRt4IuMZYDg7ChNrsAk4FHsIF1Qk1FSdHi6FEYNswSxQ8/8O36Wtx5p109DB3q\ndXAi0SUYrZJy95G0ATi/qBsoIUoM0eaPP6BOHcByxYEDWZMiUkKC0SqpGnCja6VlXdM+4ON83idS\nOFcWqFBBd0iLhJOCMsm7WAJwL+ueviMYAeVDVwylxZYt0KABYBcVVapApUqeRiQSsYJ5g1s4UGIo\nDQ4csJZL3brBCy/w2ttVGTHCOufr0QNiIuXbKhImQtVcVSR4qlWD1ashLQ2aNGHQ2Z8yYYLdAnH5\n5eq1VSRUIuUcTFcMpc3cudZra7NmZPzrTcZ8WptnnoFevWDECK+DE4kMwbpiiAUuPZmARIrl8sth\n5Uq46CLiysVx772wfj1cfbXXgYlEv0AyyQqsV1Uv6YpBRKSIglnH8DVw88msXCQUfD747TevoxCJ\nHoEkhnuB97FO8/zjPqcU+A6RYMrIgFtvhe++A6yFa7NmMGQIHDzobWgi0SCQxFDZWa4s2eM+Vw1m\nUCIFio21Jq033wz3389ZtVJYtQq2bYNGjWDCBMjM9DpIkcgVaPFQN6AjdoPbXGB60CLKm+oY5ET7\n9sGjj8LMmTBqFHTrxsKFMHCgdeg6ZQrUr+91kCLeCeYNbi9iQ3tOdJa/BRvVbUhRN1YMSgySv6Qk\na9o6ahRcfTWZmTBpEtx0kw0tKlJaBTMxrMZaJWU403FYS6VmRd1YMSgxSMGOHoXy5XV7tIhLMFsl\n+YDqrunq5OwzScR7FSoElBR27QpBLCIRLpDE8AI2NsO7wDjge2B4EGMSKTmzZ+fIBn372pCi69d7\nGJNImAvkzudMoB0wFfjIeT45yHGJlIykJGjcGF5/HdLSmDYNOnWCyy6Dhx+2fvtEJKfCEkMm8Bjw\nGzas5zRgR7CDEikx//gHzJsHX30FzZpRbtbnPDzIx9q1lhQaNdLQoiK5BdoqaTcwBTjsej2Uw7ir\n8lmK74svYNAg+Otf4cUXAfj+ezhyBDp08Dg2kSAIZqukLZxY2ewDGhZ1Y8WgxCAlIz0ddu+GunW9\njkQk6IKVGGKB7tjVgpeUGCSkUlOtkZOGHJVIFqzmqv46hpPVBVgP/AgMLmC51sBxbExpkdDbsQNm\nzMianDrV6qw//tg66RMpTQJprjoLeAQ4A6jpehQmDhiFJYfGQC/ggnyWewmYgXpwFa/89hs88ABc\ney1s2EDv3jBmDDz9NHTuDGvWeB2gSOgEkhhuAe4H5mH3MPgfhWkDbMLqKNKxJq7d8ljuAeBDQLce\niXdatoS1a+HKK60t66BBdGq5nxUr4IYb7OUHHoDjx70OVCT4AkkMDYCz8ngUph6w1TW9zXkt9zLd\ngLecaV20i3fKlbObG9auhcOHoUkTyhw9xIABsG4dNGlinfOJRLuCEoO7bqF7rnmB3PkcyEF+BPC4\ns2wMKkqScFC7NoweDcuWQeXKANSqBffe63FcIiFS0PlPL+Bl5/lQ4APXvK7OawXZjtVL+J2BXTW4\ntST7Lup4Z73p2I10OSQmJmY9T0hIICEhoZDNixRTgE1aDx6EKlWCHItIAJKSkkhKSir2ego6Q08G\nWuTxPK/pvJQBNgCdsDunl2DJZl0+y4/Fxnn4OI95aq4q4WPiRLjuOqhWjYMH4fzz4a67YPBgqFTJ\n6+BEsgWzd9WTdRwYAMwEfsDuhVgH3OM8RCJPRoZ1zNeoEYwZQ5VKGSxeDBs3wgUX2OBAOoeRSFdQ\nJskAjjjPKwKprnkVKbgYqqTpikHCy/ffw4MPwqFDMGIEJCQwf76NHlelCrz9Npx3ntdBSmkXzC4x\nwoESg4Qfnw/efx8eewyefRb69SMjA955B/78ZzjzTK8DlNJOiUHEK6mpVsTktGASCRdKDCJhLjVV\nY1BLaIVj5bNI6bZoESxYkDU5YAB06wY//eRhTCIBUGIQCZZ9+6B3b7jlFvj1V958Ey69FC65BIYM\nsfsfRMKREoNIsHTtan1pNGoELVpQftjTDB5wmFWrrM++Ro1gsgbJlTCkOgaRUNi6FR5/3MqRFi6E\nmBgWLYJNm6BPH6+Dk2ilymeRSLB/P1Sv7nUUUkooMYhECZ/PRiAtV87rSCTSqVWSSKRKS4N//hOO\nWEcD8+dD06bw2WfqXkO8ocQg4rVDh+Dbb62zpcmT6djBx8iR8MgjcM01sH691wFKaaPEIOK1mjWt\na40JE+Dll+Gyy+hSaymrV8PVV0OHDjZ+0OHDXgcqpYUSg0i46NgRli6FO++Ebt0om7yEhx6yAeUq\nVICyZb0OUEoLVT6LhKNDh+CUUyAmUn6iEo7UKkmkFDp+XONQS/7UKkmkNHjvPUhOBqxD15Ytrcdv\nda8hJUkP15+JAAANtklEQVSJQSSSpKVZVxt/+xtxu//gk0/gxx/h3HPhX/+y2SLFpcQgEkluv93a\nr1arBk2acNYHL/O/d44xcyZ8+aX1vzRjhtdBSqRTHYNIpNq40W52iI+H//4XgKQkKF8e2rXzNjQJ\nD6p8FimtjhyBSpW8jkLCkCqfRUqrAJLC/v2wYUMIYpGooMQgEo1++QVefz2rNnrlSrjsMrj7bti+\n3ePYJOwpMYhEo8xMmDULmjWDzz7j8o4+NmywHr8vvNBGkNu/3+sgJVypjkEkmn35JQwaBPXr2xVE\n48Zs2waJiTB9unW3ER/vdZASLKp8FpG8pafDm2/CK6/AqlXWaR9WpFSvnsexSVApMYhIwY4ds7as\nUmqoVZKIFCzApPDaazBvXpBjkbCmxCBS2g0fbkVMjlNPhdtug+uug9WrPYxLPKPEIFKa+Xx2H8TV\nV8Mtt8D69fTubfc8XHUVdO5sSWLLFq8DlVBSYhApzWJi4O9/h02boHlzGy7u9tspv+0nHnzQOuhr\n0MA66JPSQ5XPIpLtwAEYMcKuIh591OtopJjUKklEQi4jA+LivI5C8qNWSSISXD4f7NmTNbl+vXXz\nPXmy3Wgt0UOJQUQC88MPcN558MQTsG8fjRrB6NHWvLVVK/jqK8sdEvmUGEQkME2awPLlsHOnDRn3\nj39wZasUFi+GoUPhgQesFdPmzV4HKsWlxCAigTvzTBgzBhYtsiZL55xDTPJybr4Z1qyBnj1tcDmJ\nbKGofO4CjADigLeBl3LNvxV4zInlIHAfsCrXMqp8FglH69bBWWdBhQpeRyJ5CNdWSXHABqAzsB1Y\nCvQC1rmWaQf8ABzAkkgi0DbXepQYRCLYhg12R7WuJkIrXFsltQE2AVuAdGAy0C3XMguxpACwGDg9\nyDGJSLB98omNQ338OAAff2zVEq+9BkePehybFCrYiaEesNU1vc15LT93Al8ENSIRCb7TToMJE6Bx\nY5g4kSGPZTBnDsydC+efD+++a/dASHgqE+T1F6X85wqgP9A+r5mJiYlZzxMSEkhISChOXCISTG3a\nwJw5MHs2PPUUDB9Ok2ef5dOpN/LtwlgefxwmTbImrlJykpKSSEpKKvZ6gl3H0BarM+jiTA8BMjmx\nAvpC4GNnuU15rEd1DCKRyueDGTNg4kQYPx5iY/H5bKCg01VwHFThWvlcBqt87gT8BizhxMrn+sBs\noA+wKJ/1KDGIiBRRuFY+HwcGADOxlkdTsKRwj/MAeBqoAbwFJGPJQ0RKi99/z3qang6PPQa//OJh\nPKJO9ETEQz4fXHopVK4Mzz1H6kVtGT7chqju18/uqK5Vy+sgI1e4XjGIiOQvJsbGEe3RA3r0oGL3\n63juhuWsWQOpqdaCadgwOHzY60BLFyUGEfFW2bJw113WxUaXLnDdddT9z7O8+SYsXGijjn75pddB\nli4qShKR8HLkCOzaZf0ySbGEa6ukkqLEICI5ZGZCrMo8CqQ6BhGJbjt3wv33w1brTOHNN+HPf4bk\nZI/jikJKDCISGcqVgypVoHlzGDiQe67fwV//CtdeC716wU8/eR1g9FBiEJHIUL06vPiijSQXF0fZ\n5k247+dH2fjdbpo0gUsusQuKtDSvA418SgwiElnq1IHXX7fmSocPU/ngDp580sagbtzYGjlJ8ajy\nWUQkSqnyWUTEb9cua/bqSE5WN99FocQgItFnyhQ45xwYORJf6lEefRRatIDPP7deOKRgKkoSkeiU\nnAxPPw0rV+Ib+gTT4vsz9Jmy1KoFL70E7dp5HWDw6QY3EZG8LF5sgwVt3UpG8irGv1eWZ56BAQOs\nJ9dopsQgIlKQn3+Ghg0BOHYMUlLgT3/yOKYgU2IQEZEc1CpJRORkPPJIVq30pk02PMT06aW7klqJ\nQURKt/bt4fHHoV07Gv40i4cH+Xj6aWvF9OGH1llfaaOiJBGRzEx4/3145hk49VR8w4bz+f72PPcc\nHDwI48ZB69ZeB1l0qmMQESmu48dh4kS7Oe6++/D54OuvrauNevW8Dq7olBhERCQHVT6LiASTzwdv\nvGHdbQBLllhffq6eN6KGEoOISCCOHIEVK+C88+Bvf6PK7z+yYAGcdZb1Bp6S4nWAJUeJQUQkEKec\nAmPGwMaNcOaZXHBPRz5KuYpvXlzKqlVw9tnw7LNWWR3pVMcgInIyjh2zzvpOOQVuuomNG+G116wf\npmrVvA7OqPJZRERyUOWziEi4SEuD++6DpUsBq5rYutXjmIpAiUFEpKRlZsK550L37tC+PQvfWE7z\n5j7uvtv68gt3SgwiIiWtQgUYNAg2bYJBg7hv3UA2VmpBnT0/0KYN3H67jVEdrlTHICISCkuXQkYG\n+xu1ZdQo+PRTGyoiNoin56p8FhGJID4fxAT5CKzKZxGRCJKVFFJSoGNH66nv2DH27vU0LECJQUTE\nW5Urw5AhMGkSNGjAza0206ljGnPmeDcmhIqSRETCxdq1pL/2Lya+F8vwKsOpfW51nnoKrr765Iqd\nVMcgIhItdu0i48Ah3l96Fs8/b2NBvPtu0VejxCAiEoUyM+H33+G005wX0tOhbNmA3huulc9dgPXA\nj8DgfJYZ6cxfCbQIcjwiIhElNtaVFPbuhfr1bbQ5gjfsaDATQxwwCksOjYFewAW5lrkGOAc4F7gb\neCuI8USFpKQkr0MIG9oX2bQvskX1vqhZExYsgFatSEuDCy6AJ5+EnTtLdjPBTAxtgE3AFiAdmAx0\ny7XM9cA45/lioDpQJ4gxRbyo/tIXkfZFNu2LbFG/L84+Gxo2pFw5+Pxz2LMHGjWyrpk2bSqZTQQz\nMdQD3N1GbXNeK2yZ04MYk4hI1DjnHHjrLeteIz4e2rWzQYOKK5iJIdDa4twVI6plFhEpgtq14bnn\nYPNm6NWr+OsLZquktkAiVscAMATIBF5yLfNvIAkrZgKrqL4c+CPXujYBZwcpThGRaPUTVo8bNspg\nQTUAygEryLvy+QvneVtgUaiCExERb3QFNmBn/EOc1+5xHn6jnPkrgYtDGp2IiIiIiEQW3RCXrbB9\ncSu2D1YB3wIXhi60kAvkewHQGjgO3BiKoDwQyH5IAJKBNVj9XbQqbF/EAzOwIuw1QL+QRRZ6/8Xq\nZVcXsEzEHjfjsCKlBkBZCq+TuITorZMIZF+0A6o5z7tQuveFf7nZwGfATaEKLoQC2Q/VgbVkN/mO\nD1VwIRbIvkgEXnCexwN7sHrPaNQBO9jnlxiKfNwMp263dUNctkD2xULggPN8MdF7/0cg+wLgAeBD\nYFfIIgutQPZDb+Aj7H4ggN2hCi7EAtkXO4CqzvOqWGI4HqL4Qm0+sK+A+UU+boZTYtANcdkC2Rdu\nd5J9RhBtAv1edCO7S5VovBcmkP1wLlATmAMsA/qGJrSQC2RfjAGaAL9hxScPhia0sFTk42Y4XVrp\nhrhsRflMVwD9gfZBisVrgeyLEcDjzrIxRE6vwUURyH4oi7Xs6wRUwq4qF2Fly9EkkH0xFCtiSsDu\ngZoFXAQcDF5YYa1Ix81wSgzbgTNc02eQfUmc3zKnO69Fm0D2BViF8xisjqGgS8lIFsi+aEn2TZLx\nWDPpdGBa0KMLnUD2w1as+CjVeczDDobRlhgC2ReXAsOc5z8Bm4HzsSup0iaij5u6IS5bIPuiPlbO\n2jakkYVeIPvCbSzR2SopkP3QCPgaq5ythFVGNg5diCETyL54DXjGeV4HSxw1QxSfFxoQWOVzRB43\ndUNctsL2xdtYhVqy81gS6gBDKJDvhV+0JgYIbD88grVMWg0MDGl0oVXYvogHpmPHidVYxXy0eg+r\nS0nDrhr7U3qPmyIiIiIiIiIiIiIiIiIiIiIiIiIiIiLB9FdsuNjzXa81oODuh0tKP6zDPv99JO+W\nwDpvB+q6psdQ8M18IiKSyxSs24tE12sNKFpiONluYW7H+rgvyfXOwbr3EPFUOPWuKlIUlbG+5QcA\nPfNZpgHWX9D3zqOd83oC1lXxp9hdwpcDc4FPsK4WXsR6Jl2CDYTUMJ/15+6YLBGYACzAujk+M5/t\ngw0uswrrzuEFbAyJVsBEYDlQARtox58oejnLr3bi8zsEPO+sZyFQO59YRUSi3q3Av53n88i+zb8B\n2VcMFYHyzvNzgaXO8wTsgHqma3of1qdOOayDsURn3kDg9Ty23w/YSXZRUj+sb55lrm3mt/2u2Kh7\nFZzp6s7fOeTsrsA/fRrwC1AL6wfpG7LHH8gErnWevwQ8kUesIkWiKwaJVL2AD5znHzjTuZXD+pRa\nBbxPzvL6JdjB1m8pNjxiGtanzEzn9TVYssnNh/Xo2sJ5vOu8/ilwrJDtd8aGYzzqTO93rTf3VUgM\nNmRpEtY3VgZ2VdHRmZ8GfO48/z6fWEWKJJy63RYJVE1sHIqm2AE6zvn7aK7lHsJG8urrLHPUNe9w\nrmWPuZ5nuqYzyf93kte4D0cC2L5/3Ii85NVPfu7XYlyvpbteLyhWkYDpikEi0c3AeOzs+CysC/LN\n2Ni3blWB353nt2EH55ISyGBA+W1/FnAHVtQEUMP5e5Ds4Sj9fNjVzeVkFyXdgtWJiASFEoNEoluA\nqble+8h53Uf22fSbWOuhFViT1kOu5X25nuc3olV+8wp63S+/7c/EWlMtw+onHnZefxerN/FXPvv9\njo1QN8dZ1zKsS+mifA4RERERERERERERERERERERERERERERERERERGR8Pb/AaEKqeso0GgfAAAA\nAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7fb07d1e7b10>"
       ]
      }
     ],
     "prompt_number": 185
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Sanity check\n",
      "\"\"\"\n",
      "print pd.DataFrame({\"taus\": mda_taus, \"alarm_fractions\": mda_alarm_fractions, \"error_ratios\": mda_error_ratios})\n",
      "print pd.DataFrame({\"alarm_lengths\": aa_alarm_lengths, \"alarm_fractions\": aa_alarm_fractions, \"error_ratios\": aa_error_ratios})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "    alarm_fractions  error_ratios     taus\n",
        "0          0.004139      0.986120     1000\n",
        "1          0.008179      0.972447     2000\n",
        "2          0.016086      0.946551     4000\n",
        "3          0.031394      0.908121     8000\n",
        "4          0.060768      0.853325    16000\n",
        "5          0.115415      0.773565    32000\n",
        "6          0.212053      0.662834    64000\n",
        "7          0.372906      0.504972   128000\n",
        "8          0.597422      0.309198   256000\n",
        "9          0.829952      0.122229   512000\n",
        "10         0.965684      0.023203  1024000\n",
        "11         0.997711      0.001036  2048000\n",
        "12         1.000000      0.000104  4096000\n",
        "13         1.000000      0.000104  8192000\n",
        "    alarm_fractions  alarm_lengths  error_ratios\n",
        "0          0.000643           1000      0.995857\n",
        "1          0.001285           2000      0.994199\n",
        "2          0.002566           4000      0.989538\n",
        "3          0.005110           8000      0.979283\n",
        "4          0.010126          16000      0.963435\n",
        "5          0.019918          32000      0.932981\n",
        "6          0.038687          64000      0.888958\n",
        "7          0.074073         128000      0.825357\n",
        "8          0.138369         256000      0.738865\n",
        "9          0.249336         512000      0.613528\n",
        "10         0.423087        1024000      0.447586\n",
        "11         0.647197        2048000      0.254713\n",
        "12         0.856772        4096000      0.093226\n",
        "13         0.972142        8192000      0.017091\n"
       ]
      }
     ],
     "prompt_number": 187
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "TODO:\n",
      "For AUC, do we need regular x-axis step sizes?\n",
      "Figure out how to calculate AUC. lab7 has an example in BIDMach. roc function?\n",
      "explore coarse tuning for u. See if that improves curve. Currently the curve looks a lot worse than papers? Read papers\n",
      "Figure out how ETAS fits into this. Can it be plotted on the same axes?\n",
      "look into existing training algorithms in sk-learn/bidmach/spark (stochastic gradient descent?)\n",
      "Explore increasing size of data (right now set to just look at 2013 data)\n",
      "\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 188,
       "text": [
        "'\\nTODO:\\nFor AUC, do we need regular x-axis step sizes?\\nFigure out how to calculate AUC. lab7 has an example in BIDMach. roc function?\\nexplore coarse tuning for u. See if that improves curve. Currently the curve looks a lot worse than papers? Read papers\\nFigure out how ETAS fits into this. Can it be plotted on the same axes?\\nlook into existing training algorithms in sk-learn/bidmach/spark (stochastic gradient descent?)\\nExplore increasing size of data (right now set to just look at 2013 data)\\n'"
       ]
      }
     ],
     "prompt_number": 188
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Training MDA means tuning u using training data to minimize training AUC, where AUC is computed by varying tau?\n",
      "Evaluating MDA means computing AUC for validation/test data?\n",
      "\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 189,
       "text": [
        "'\\nTraining MDA means tuning u using training data to minimize training AUC, where AUC is computed by varying tau?\\nEvaluating MDA means computing AUC for validation/test data?\\n'"
       ]
      }
     ],
     "prompt_number": 189
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}