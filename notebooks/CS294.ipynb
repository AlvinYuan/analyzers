{
 "metadata": {
  "name": "",
  "signature": "sha256:c35dfb2e6e0da9ec8c049b2cefb8c6bb56041da7ecfa812aa384fde901f16d4e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from ggplot import *\n",
      "import datetime\n",
      "import time\n",
      "import urllib\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from pandas import read_csv\n",
      "from pprint import pprint\n",
      "from datetime import timedelta"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Reads all year.catalog.csv files in github repo.\n",
      "Loads it all into one DataFrame.\n",
      "Does not remove null values, but data seems clean in this sense already.\n",
      "XXX: Note that the row index number appears multiple times. Use iloc and related instead of loc?\n",
      "\"\"\"\n",
      "def load_data(YEAR_MIN=1932, YEAR_MAX=2013):\n",
      "    FILE_DIR = \"../data_from_curators/\"\n",
      "    df = pd.DataFrame()\n",
      "    for yr in range(YEAR_MIN, YEAR_MAX+1):\n",
      "        filepath = FILE_DIR + \"%d.catalog.csv\" % yr\n",
      "        df = df.append(pd.read_csv(filepath))\n",
      "    # Convert time fields to a datetime object\n",
      "    df[\"datetime\"] = pd.to_datetime(df.apply(lambda row: row[\"YYYY/MM/DD\"] + \" \" + row[\"HH:mm:SS.ss\"], axis=1))\n",
      "    return df\n",
      "\n",
      "# May take ~ 1 minute\n",
      "full_data = load_data(2013, 2013)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Some sanity checks\n",
      "\"\"\"\n",
      "print full_data.info()\n",
      "print full_data[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 16091 entries, 0 to 16090\n",
        "Data columns (total 13 columns):\n",
        "YYYY/MM/DD     16091 non-null object\n",
        "HH:mm:SS.ss    16091 non-null object\n",
        "ET             16091 non-null object\n",
        "MAG            16091 non-null float64\n",
        "M              16091 non-null object\n",
        "LAT            16091 non-null float64\n",
        "LON            16091 non-null float64\n",
        "DEPTH          16091 non-null float64\n",
        "Q              16091 non-null object\n",
        "EVID           16091 non-null float64\n",
        "NPH            16091 non-null float64\n",
        "NGRM           16091 non-null float64\n",
        "datetime       16091 non-null datetime64[ns]\n",
        "dtypes: datetime64[ns](1), float64(7), object(5)None\n",
        "   YYYY/MM/DD  HH:mm:SS.ss  ET   MAG  M     LAT      LON  DEPTH  Q      EVID  \\\n",
        "0  2013/01/01  00:55:30.86  le  0.75  l  33.973 -116.807   13.9  A  15269305   \n",
        "1  2013/01/01  01:22:48.22  le  1.61  l  34.909 -119.596   10.0  A  15269313   \n",
        "2  2013/01/01  01:30:15.24  le  0.28  l  35.946 -117.662    5.0  A  15269321   \n",
        "3  2013/01/01  01:50:54.74  le  0.64  l  33.704 -116.751   19.5  A  15269329   \n",
        "4  2013/01/01  02:00:11.27  le  0.83  l  33.276 -116.780   13.0  A  15269337   \n",
        "5  2013/01/01  02:47:58.48  le  1.87  l  33.782 -118.358    8.2  A  15269353   \n",
        "6  2013/01/01  03:01:55.10  le  1.13  l  34.177 -117.364   12.8  A  15269361   \n",
        "7  2013/01/01  03:29:39.68  le  1.66  l  36.155 -118.064    0.5  A  15269369   \n",
        "8  2013/01/01  06:10:05.13  le  1.01  l  36.151 -118.073    5.6  C  15269377   \n",
        "9  2013/01/01  06:36:26.07  le  0.67  l  33.658 -116.733   15.7  A  15269385   \n",
        "\n",
        "   NPH  NGRM                   datetime  \n",
        "0   32     0 2013-01-01 00:55:30.860000  \n",
        "1   27     0 2013-01-01 01:22:48.220000  \n",
        "2    9     0 2013-01-01 01:30:15.240000  \n",
        "3   18     0 2013-01-01 01:50:54.740000  \n",
        "4   36     0 2013-01-01 02:00:11.270000  \n",
        "5   59     0 2013-01-01 02:47:58.480000  \n",
        "6   54     0 2013-01-01 03:01:55.100000  \n",
        "7   38     0 2013-01-01 03:29:39.680000  \n",
        "8   14     0 2013-01-01 06:10:05.130000  \n",
        "9   38     0 2013-01-01 06:36:26.070000  \n"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Split data into training, validation, and test sets.\n",
      "Splits based on order: training is earliest data, validation is middle, test is latest.\n",
      "Cannot split randomly because we believe there is time clustering.\n",
      "This may introduce confounds with quality of data though (is earlier data more reliable?).\n",
      "For now, assume data quality is constant across time.\n",
      "\"\"\"\n",
      "def split_data(data, training_size, validation_size, test_size):\n",
      "    assert(training_size + validation_size + test_size == 1)\n",
      "    validation_start = int(len(data) * training_size)\n",
      "    test_start = int(len(data) * (training_size + validation_size))\n",
      "    return (data[:validation_start], data[validation_start:test_start], data[test_start:])\n",
      "\n",
      "training, validation, test = split_data(full_data, .6, .2, .2)\n",
      "assert(len(training) + len(validation) + len(test) == len(full_data))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Mostly copied from mda_with_curator.ipynb\n",
      "TODO: translate all of this to matrix stuff.\n",
      "\"\"\"\n",
      "def basic_mda(tau, u, mag):\n",
      "    return tau * (u ** mag)\n",
      "\n",
      "def mda(data, tau=0.7, funct=basic_mda):\n",
      "    \"\"\"\n",
      "    Uses basic MDA model (tau*u^mag) to predict earthquakes.\n",
      "    Returns tuple of (start, end) representing date range when alarm should be on.\n",
      "    MAG: list of earthquake magnitudes\n",
      "    DT: list of earthquake datetimes in python datetime format\n",
      "    (MAG and DT have the same length and come from earthquakes data frame)\n",
      "    \"\"\"\n",
      "    \n",
      "    tau = 0.7 # we will figure out what tau is later\n",
      "    u = 4 # we will add fancy tuning functionality later\n",
      "    alarms = pd.DataFrame({\"start\": data.apply(lambda row: row[\"datetime\"] + datetime.timedelta(seconds=1), axis=1),\n",
      "                           \"end\": data.apply(lambda row: row[\"datetime\"] + datetime.timedelta(seconds=funct(tau, u, row[\"MAG\"])), axis=1)\n",
      "                           })\n",
      "    return alarms\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 85
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Returns the fraction of time the alarm is on.\n",
      "Assumes arguments are sorted by time.\n",
      "TODO: Figure out a way if posible to calculate this with matrices? Looping through is slow. Matrix is fast.\n",
      "\"\"\"\n",
      "def alarm_fraction(data, alarm_ranges):\n",
      "    time_frame = data.iloc[-1][\"datetime\"] - data.iloc[0][\"datetime\"]\n",
      "    alarm_time = datetime.timedelta(seconds=0);\n",
      "    latest_alarm_end = None\n",
      "    for i in range(len(alarm_ranges)): # XXX: not translatable to matrix operations\n",
      "        end = alarm_ranges.iloc[i][\"end\"]\n",
      "        start = alarm_ranges.iloc[i][\"start\"]\n",
      "        if not latest_alarm_end or latest_alarm_end < start:\n",
      "            alarm_time += end - start\n",
      "            latest_alarm_end = end\n",
      "        elif latest_alarm_end < end:\n",
      "            # latest_alarm_end is after start of alarm but before end of alarm\n",
      "            alarm_time += end - latest_alarm_end\n",
      "            latest_alarm_end = end\n",
      "        else:\n",
      "            #latest_alarm_end is after alarm completely\n",
      "            pass\n",
      "    return alarm_time.seconds / float(time_frame.seconds)\n",
      "\n",
      "alarm_ranges = mda(validation)\n",
      "print alarm_fraction(validation, alarm_ranges)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.173516583431\n"
       ]
      }
     ],
     "prompt_number": 103
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Returns the number of correct predictions.\n",
      "Assumes arguments are sorted by time.\n",
      "TODO: SPEED THIS UP. Prohibitively slow (order of minutes)\n",
      "\"\"\"\n",
      "def prediction_positives(data, alarm_ranges):\n",
      "    \"\"\"\n",
      "        Returns 1 if row (event) happened in an alarm\n",
      "        Assumes alarm_ranges is sorted by time\n",
      "    \"\"\"\n",
      "    def caught(row, alarm_ranges):\n",
      "        return alarm_ranges.apply(lambda alarm: 1 if alarm[\"start\"] < row[\"datetime\"] and row[\"datetime\"] < alarm[\"end\"] else 0, axis=1).max()\n",
      "    return data.apply(lambda row: caught(row, alarm_ranges), axis=1).sum()\n",
      "print prediction_positives(validation, alarm_ranges)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "8\n"
       ]
      }
     ],
     "prompt_number": 102
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}