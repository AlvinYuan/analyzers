{
 "metadata": {
  "name": "",
  "signature": "sha256:c92ae63100a0a537d715c60037adb4494a7a83268482e822d74c1b2223924a65"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from ggplot import *\n",
      "import datetime\n",
      "import time\n",
      "import urllib\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from pandas import read_csv\n",
      "from pprint import pprint\n",
      "from datetime import timedelta"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 224
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Reads all year.catalog.csv files in github repo.\n",
      "Loads it all into one DataFrame.\n",
      "Does not remove null values, but data seems clean in this sense already.\n",
      "XXX: Note that the row index number appears multiple times. Use iloc and related instead of loc?\n",
      "\"\"\"\n",
      "def load_data(YEAR_MIN=1932, YEAR_MAX=2013):\n",
      "    FILE_DIR = \"../data_from_curators/\"\n",
      "    df = pd.DataFrame()\n",
      "    for yr in range(YEAR_MIN, YEAR_MAX+1):\n",
      "        filepath = FILE_DIR + \"%d.catalog.csv\" % yr\n",
      "        df = df.append(pd.read_csv(filepath))\n",
      "    # Convert time fields to a datetime object\n",
      "    df[\"datetime\"] = pd.to_datetime(df.apply(lambda row: row[\"YYYY/MM/DD\"] + \" \" + row[\"HH:mm:SS.ss\"], axis=1))\n",
      "    return df\n",
      "\n",
      "# May take ~ 1 minute\n",
      "full_data = load_data(2013, 2013)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 256
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Some sanity checks\n",
      "\"\"\"\n",
      "print full_data.info()\n",
      "print full_data[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 16091 entries, 0 to 16090\n",
        "Data columns (total 13 columns):\n",
        "YYYY/MM/DD     16091 non-null object\n",
        "HH:mm:SS.ss    16091 non-null object\n",
        "ET             16091 non-null object\n",
        "MAG            16091 non-null float64\n",
        "M              16091 non-null object\n",
        "LAT            16091 non-null float64\n",
        "LON            16091 non-null float64\n",
        "DEPTH          16091 non-null float64\n",
        "Q              16091 non-null object\n",
        "EVID           16091 non-null float64\n",
        "NPH            16091 non-null float64\n",
        "NGRM           16091 non-null float64\n",
        "datetime       16091 non-null datetime64[ns]\n",
        "dtypes: datetime64[ns](1), float64(7), object(5)None\n",
        "   YYYY/MM/DD  HH:mm:SS.ss  ET   MAG  M     LAT      LON  DEPTH  Q      EVID  \\\n",
        "0  2013/01/01  00:55:30.86  le  0.75  l  33.973 -116.807   13.9  A  15269305   \n",
        "1  2013/01/01  01:22:48.22  le  1.61  l  34.909 -119.596   10.0  A  15269313   \n",
        "2  2013/01/01  01:30:15.24  le  0.28  l  35.946 -117.662    5.0  A  15269321   \n",
        "3  2013/01/01  01:50:54.74  le  0.64  l  33.704 -116.751   19.5  A  15269329   \n",
        "4  2013/01/01  02:00:11.27  le  0.83  l  33.276 -116.780   13.0  A  15269337   \n",
        "5  2013/01/01  02:47:58.48  le  1.87  l  33.782 -118.358    8.2  A  15269353   \n",
        "6  2013/01/01  03:01:55.10  le  1.13  l  34.177 -117.364   12.8  A  15269361   \n",
        "7  2013/01/01  03:29:39.68  le  1.66  l  36.155 -118.064    0.5  A  15269369   \n",
        "8  2013/01/01  06:10:05.13  le  1.01  l  36.151 -118.073    5.6  C  15269377   \n",
        "9  2013/01/01  06:36:26.07  le  0.67  l  33.658 -116.733   15.7  A  15269385   \n",
        "\n",
        "   NPH  NGRM                   datetime  \n",
        "0   32     0 2013-01-01 00:55:30.860000  \n",
        "1   27     0 2013-01-01 01:22:48.220000  \n",
        "2    9     0 2013-01-01 01:30:15.240000  \n",
        "3   18     0 2013-01-01 01:50:54.740000  \n",
        "4   36     0 2013-01-01 02:00:11.270000  \n",
        "5   59     0 2013-01-01 02:47:58.480000  \n",
        "6   54     0 2013-01-01 03:01:55.100000  \n",
        "7   38     0 2013-01-01 03:29:39.680000  \n",
        "8   14     0 2013-01-01 06:10:05.130000  \n",
        "9   38     0 2013-01-01 06:36:26.070000  \n"
       ]
      }
     ],
     "prompt_number": 226
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Split data into training, validation, and test sets.\n",
      "Splits based on order: training is earliest data, validation is middle, test is latest.\n",
      "Cannot split randomly because we believe there is time clustering.\n",
      "This may introduce confounds with quality of data though (is earlier data more reliable?).\n",
      "For now, assume data quality is constant across time.\n",
      "\"\"\"\n",
      "def split_data(data, training_size, validation_size, test_size):\n",
      "    assert(training_size + validation_size + test_size == 1)\n",
      "    validation_start = int(len(data) * training_size)\n",
      "    test_start = int(len(data) * (training_size + validation_size))\n",
      "    return (data[:validation_start], data[validation_start:test_start], data[test_start:])\n",
      "\n",
      "training, validation, test = split_data(full_data, .6, .2, .2)\n",
      "assert(len(training) + len(validation) + len(test) == len(full_data))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 227
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Convert data to matrix\n",
      "\"\"\"\n",
      "event_times = np.matrix(training[\"datetime\"].values).getT()\n",
      "event_magnitudes = np.matrix(training[\"MAG\"].values).getT()\n",
      "num_events = event_times.shape[0]\n",
      "print num_events"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "9654\n"
       ]
      }
     ],
     "prompt_number": 280
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def mda(event_times, event_magnitudes, tau=700, u=4):\n",
      "    \"\"\"\n",
      "    Uses basic MDA model (tau*u^mag) to predict earthquakes.\n",
      "    Returns matrix of (start, end) representing date range when alarm should be on.\n",
      "    \"\"\"\n",
      "    # MDA\n",
      "    num_events = event_times.shape[0]\n",
      "    start_offset = np.timedelta64(1, \"ms\")\n",
      "\n",
      "    event_times2 = np.repeat(event_times, 2, axis=1)\n",
      "    start_offsets = start_offset * np.ones([num_events, 1])\n",
      "    stop_offsets = np.timedelta64(1, \"ms\") * np.floor( tau * np.power(u, event_magnitudes) )\n",
      "    offsets = np.concatenate((np.mat(start_offsets), np.mat(stop_offsets)), axis=1)\n",
      "    alarms = event_times2 + offsets\n",
      "    \n",
      "    \"\"\"\n",
      "    Clean alarm data so that alarms do not overlap.\n",
      "    Clean alarm data so that whether an event was predicted can be checked by the alarm range in the same row\n",
      "    TODO: can this be done as a matrix operation\n",
      "    \"\"\"\n",
      "    cutoff_offset = - 2 * start_offset\n",
      "    for i in range(1, alarms.shape[0]):\n",
      "        previous_alarm_end = alarms[i-1, 1]\n",
      "        if alarms[i, 0] < previous_alarm_end:\n",
      "            # latest alarm after this event\n",
      "            # This event is predicted\n",
      "            # There is an overlap in alarm ranges\n",
      "            cutoff = alarms[i, 0] + cutoff_offset # result should be before event i timestamp\n",
      "            # Start alarm for event i before event i to indicate predicted\n",
      "            alarms[i, 0] = cutoff\n",
      "            # Update alarms to not overlap\n",
      "            alarms[i-1, 1] = cutoff\n",
      "            # Update latest alarm\n",
      "            if alarms[i, 1] < previous_alarm_end:\n",
      "                alarms[i, 1] = previous_alarm_end\n",
      "        # else:\n",
      "        # latest alarm ends before this event\n",
      "        # No overlap, no update\n",
      "\n",
      "    # cutoff final alarm so it does not contribute to alarm_fraction\n",
      "    alarms[-1, 1] = alarms[-1, 0] + cutoff_offset\n",
      "    return alarms"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 258
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "% time\n",
      "alarms = mda(event_times, event_magnitudes)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 5 \u00b5s, sys: 0 ns, total: 5 \u00b5s\n",
        "Wall time: 8.11 \u00b5s\n"
       ]
      }
     ],
     "prompt_number": 259
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Returns the fraction of time the alarm is on.\n",
      "Assumes arguments are sorted by time and alarms do not overlap.\n",
      "\"\"\"\n",
      "def alarm_fraction(event_times, alarms):\n",
      "    time_frame = event_times[-1,0] - event_times[0, 0]\n",
      "    alarm_time = np.sum(alarms[:,1] - alarms[:,0])\n",
      "#     print time_frame / np.timedelta64(1,\"D\"), alarm_time / np.timedelta64(1,\"D\")\n",
      "    return alarm_time / time_frame\n",
      "\n",
      "% time \n",
      "print alarm_fraction(event_times, alarms)\n",
      "\n",
      "# print event_times[0,0]\n",
      "# print event_times[-1,0]\n",
      "# print (validation[\"datetime\"].values[-1] - validation[\"datetime\"].values[0])\n",
      "# print (validation.iloc[-1][\"datetime\"] - validation.iloc[0][\"datetime\"]).total_seconds()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
        "Wall time: 25 \u00b5s\n",
        "0.00290736288229\n"
       ]
      }
     ],
     "prompt_number": 260
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Returns the number of correct predictions.\n",
      "Assumes alarm for event i starts before event i if a previous alarm predicted event i.\n",
      "\"\"\"\n",
      "def prediction_positives(event_times, alarms):\n",
      "    num_events = event_times.shape[1]\n",
      "    deltas = event_times > alarms[:,0]\n",
      "    return np.sum(deltas)\n",
      "\n",
      "def error_ratio(event_times, alarms):\n",
      "    num_events = event_times.shape[0]\n",
      "    return (num_events - prediction_positives(event_times, alarms)) / float(num_events)\n",
      "% time\n",
      "print prediction_positives(event_times, alarms), error_ratio(event_times, alarms)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
        "Wall time: 5.01 \u00b5s\n",
        "98 0.98984876735\n"
       ]
      }
     ],
     "prompt_number": 261
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Attempt some coarse tuning of tau\n",
      "\"\"\"\n",
      "% time\n",
      "\n",
      "taus = [1000, 2000, 4000, 8000, 16000, 32000, 64000, 128000, 256000, 516000, 1048000]\n",
      "# taus = xrange(1000, 1048000, 10000)\n",
      "alarm_fractions = []\n",
      "error_ratios = []\n",
      "\n",
      "for tau in taus:\n",
      "    alarms = mda(event_times, event_magnitudes, tau)\n",
      "    alarm_fractions.append(alarm_fraction(event_times, alarms))\n",
      "    error_ratios.append(error_ratio(event_times, alarms))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 3 \u00b5s, sys: 0 ns, total: 3 \u00b5s\n",
        "Wall time: 5.96 \u00b5s\n"
       ]
      }
     ],
     "prompt_number": 275
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Plot the commonly used chart\n",
      "HW1 has some plotting examples\n",
      "\"\"\"\n",
      "import pylab\n",
      "%matplotlib inline\n",
      "pylab.xlabel(\"Alarm Fraction\")\n",
      "pylab.ylabel(\"Error Ratio\")\n",
      "pylab.plot(alarm_fractions, error_ratios)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 276,
       "text": [
        "[<matplotlib.lines.Line2D at 0x7fc870ad8490>]"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEPCAYAAABGP2P1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7fc870b42390>"
       ]
      }
     ],
     "prompt_number": 276
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Print some values\n",
      "\"\"\"\n",
      "\n",
      "print pd.DataFrame({\"taus\": taus, \"alarm_fractions\": alarm_fractions, \"error_ratios\": error_ratios}).head()\n",
      "print pd.DataFrame({\"taus\": taus, \"alarm_fractions\": alarm_fractions, \"error_ratios\": error_ratios}).tail()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   alarm_fractions  error_ratios   taus\n",
        "0         0.004139      0.986120   1000\n",
        "1         0.008179      0.972447   2000\n",
        "2         0.016086      0.946551   4000\n",
        "3         0.031394      0.908121   8000\n",
        "4         0.060768      0.853325  16000\n",
        "    alarm_fractions  error_ratios     taus\n",
        "6          0.212053      0.662834    64000\n",
        "7          0.372906      0.504972   128000\n",
        "8          0.597422      0.309198   256000\n",
        "9          0.832045      0.119950   516000\n",
        "10         0.968033      0.020820  1048000\n"
       ]
      }
     ],
     "prompt_number": 277
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "TODO:\n",
      "For AUC, do we need regular x-axis step sizes?\n",
      "Figure out how to calculate AUC. lab7 has an example in BIDMach. roc function?\n",
      "explore coarse tuning for u. See if that improves curve. Currently the curve looks a lot worse than papers? Read papers\n",
      "compare curve against tuned simple alarm (constant time)\n",
      "Figure out how ETAS fits into this. Can it be plotted on the same axes?\n",
      "look into existing training algorithms in sk-learn/bidmach/spark (stochastic gradient descent?)\n",
      "Explore increasing size of data (right now set to just look at 2013 data)\n",
      "\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 281,
       "text": [
        "'\\nTODO:\\nFor AUC, do we need regular x-axis step sizes?\\nFigure out how to calculate AUC. lab7 has an example in BIDMach. roc function?\\nexplore coarse tuning for u. See if that improves curve. Currently the curve looks a lot worse than papers? Read papers\\ncompare curve against tuned simple alarm (constant time)\\nFigure out how ETAS fits into this. Can it be plotted on the same axes?\\nlook into existing training algorithms in sk-learn/bidmach/spark (stochastic gradient descent?)\\nExplore increasing size of data (right now set to just look at 2013 data)\\n'"
       ]
      }
     ],
     "prompt_number": 281
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}