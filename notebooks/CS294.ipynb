{
 "metadata": {
  "name": "",
  "signature": "sha256:ff9e17680066461e4014fd2b82642870c045f6e37ac0f67636a02a28758a7616"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from ggplot import *\n",
      "import datetime\n",
      "import time\n",
      "import urllib\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from pandas import read_csv\n",
      "from pprint import pprint\n",
      "from datetime import timedelta"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 224
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Reads all year.catalog.csv files in github repo.\n",
      "Loads it all into one DataFrame.\n",
      "Does not remove null values, but data seems clean in this sense already.\n",
      "XXX: Note that the row index number appears multiple times. Use iloc and related instead of loc?\n",
      "\"\"\"\n",
      "def load_data(YEAR_MIN=1932, YEAR_MAX=2013):\n",
      "    FILE_DIR = \"../data_from_curators/\"\n",
      "    df = pd.DataFrame()\n",
      "    for yr in range(YEAR_MIN, YEAR_MAX+1):\n",
      "        filepath = FILE_DIR + \"%d.catalog.csv\" % yr\n",
      "        df = df.append(pd.read_csv(filepath))\n",
      "    # Convert time fields to a datetime object\n",
      "    df[\"datetime\"] = pd.to_datetime(df.apply(lambda row: row[\"YYYY/MM/DD\"] + \" \" + row[\"HH:mm:SS.ss\"], axis=1))\n",
      "    return df\n",
      "\n",
      "# May take ~ 1 minute\n",
      "full_data = load_data(2013, 2013)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 225
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Some sanity checks\n",
      "\"\"\"\n",
      "print full_data.info()\n",
      "print full_data[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 16091 entries, 0 to 16090\n",
        "Data columns (total 13 columns):\n",
        "YYYY/MM/DD     16091 non-null object\n",
        "HH:mm:SS.ss    16091 non-null object\n",
        "ET             16091 non-null object\n",
        "MAG            16091 non-null float64\n",
        "M              16091 non-null object\n",
        "LAT            16091 non-null float64\n",
        "LON            16091 non-null float64\n",
        "DEPTH          16091 non-null float64\n",
        "Q              16091 non-null object\n",
        "EVID           16091 non-null float64\n",
        "NPH            16091 non-null float64\n",
        "NGRM           16091 non-null float64\n",
        "datetime       16091 non-null datetime64[ns]\n",
        "dtypes: datetime64[ns](1), float64(7), object(5)None\n",
        "   YYYY/MM/DD  HH:mm:SS.ss  ET   MAG  M     LAT      LON  DEPTH  Q      EVID  \\\n",
        "0  2013/01/01  00:55:30.86  le  0.75  l  33.973 -116.807   13.9  A  15269305   \n",
        "1  2013/01/01  01:22:48.22  le  1.61  l  34.909 -119.596   10.0  A  15269313   \n",
        "2  2013/01/01  01:30:15.24  le  0.28  l  35.946 -117.662    5.0  A  15269321   \n",
        "3  2013/01/01  01:50:54.74  le  0.64  l  33.704 -116.751   19.5  A  15269329   \n",
        "4  2013/01/01  02:00:11.27  le  0.83  l  33.276 -116.780   13.0  A  15269337   \n",
        "5  2013/01/01  02:47:58.48  le  1.87  l  33.782 -118.358    8.2  A  15269353   \n",
        "6  2013/01/01  03:01:55.10  le  1.13  l  34.177 -117.364   12.8  A  15269361   \n",
        "7  2013/01/01  03:29:39.68  le  1.66  l  36.155 -118.064    0.5  A  15269369   \n",
        "8  2013/01/01  06:10:05.13  le  1.01  l  36.151 -118.073    5.6  C  15269377   \n",
        "9  2013/01/01  06:36:26.07  le  0.67  l  33.658 -116.733   15.7  A  15269385   \n",
        "\n",
        "   NPH  NGRM                   datetime  \n",
        "0   32     0 2013-01-01 00:55:30.860000  \n",
        "1   27     0 2013-01-01 01:22:48.220000  \n",
        "2    9     0 2013-01-01 01:30:15.240000  \n",
        "3   18     0 2013-01-01 01:50:54.740000  \n",
        "4   36     0 2013-01-01 02:00:11.270000  \n",
        "5   59     0 2013-01-01 02:47:58.480000  \n",
        "6   54     0 2013-01-01 03:01:55.100000  \n",
        "7   38     0 2013-01-01 03:29:39.680000  \n",
        "8   14     0 2013-01-01 06:10:05.130000  \n",
        "9   38     0 2013-01-01 06:36:26.070000  \n"
       ]
      }
     ],
     "prompt_number": 226
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Split data into training, validation, and test sets.\n",
      "Splits based on order: training is earliest data, validation is middle, test is latest.\n",
      "Cannot split randomly because we believe there is time clustering.\n",
      "This may introduce confounds with quality of data though (is earlier data more reliable?).\n",
      "For now, assume data quality is constant across time.\n",
      "\"\"\"\n",
      "def split_data(data, training_size, validation_size, test_size):\n",
      "    assert(training_size + validation_size + test_size == 1)\n",
      "    validation_start = int(len(data) * training_size)\n",
      "    test_start = int(len(data) * (training_size + validation_size))\n",
      "    return (data[:validation_start], data[validation_start:test_start], data[test_start:])\n",
      "\n",
      "training, validation, test = split_data(full_data, .6, .2, .2)\n",
      "assert(len(training) + len(validation) + len(test) == len(full_data))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 227
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Convert data to matrix\n",
      "\"\"\"\n",
      "event_times = np.matrix(validation[\"datetime\"].values).getT()\n",
      "event_magnitudes = np.matrix(validation[\"MAG\"].values).getT()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 228
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def mda(event_times, event_magnitudes, tau=700, u=4):\n",
      "    \"\"\"\n",
      "    Uses basic MDA model (tau*u^mag) to predict earthquakes.\n",
      "    Returns matrix of (start, end) representing date range when alarm should be on.\n",
      "    \"\"\"\n",
      "    # MDA\n",
      "    start_offset = np.timedelta64(1, \"ms\")\n",
      "    event_times2 = np.repeat(event_times, 2, axis=1)\n",
      "    num_events = event_times2.shape[0]\n",
      "    start_offsets = start_offset * np.ones([num_events, 1])\n",
      "    stop_offsets = np.timedelta64(1, \"ms\") * np.floor( tau * np.power(u, event_magnitudes) )\n",
      "    offsets = np.concatenate((np.mat(start_offsets), np.mat(stop_offsets)), axis=1)\n",
      "    alarms = event_times2 + offsets\n",
      "    \n",
      "    \"\"\"\n",
      "    Clean alarm data so that alarms do not overlap.\n",
      "    Clean alarm data so that whether an event was predicted can be checked by the alarm range in the same row\n",
      "    TODO: can this be done as a matrix operation\n",
      "    \"\"\"\n",
      "    cutoff_offset = - 2 * start_offset\n",
      "    for i in range(1, alarms.shape[0]):\n",
      "        previous_alarm_end = alarms[i-1, 1]\n",
      "        if alarms[i, 0] < previous_alarm_end:\n",
      "            # latest alarm after this event\n",
      "            # This event is predicted\n",
      "            # There is an overlap in alarm ranges\n",
      "            cutoff = alarms[i, 0] + cutoff_offset # result should be before event i timestamp\n",
      "            # Start alarm for event i before event i to indicate predicted\n",
      "            alarms[i, 0] = cutoff\n",
      "            # Update alarms to not overlap\n",
      "            alarms[i-1, 1] = cutoff\n",
      "            # Update latest alarm\n",
      "            if alarms[i, 1] < previous_alarm_end:\n",
      "                alarms[i, 1] = previous_alarm_end\n",
      "        # else:\n",
      "        # latest alarm ends before this event\n",
      "        # No overlap, no update    \n",
      "    return alarms"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 229
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "% time\n",
      "alarms = mda(event_times, event_magnitudes)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 2 \u00b5s, sys: 0 ns, total: 2 \u00b5s\n",
        "Wall time: 5.96 \u00b5s\n"
       ]
      }
     ],
     "prompt_number": 230
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Returns the fraction of time the alarm is on.\n",
      "Assumes arguments are sorted by time and alarms do not overlap.\n",
      "\"\"\"\n",
      "def alarm_fraction(event_times, alarms):\n",
      "    time_frame = event_times[-1,0] - event_times[0, 0]\n",
      "    alarm_time = np.sum(alarms[:,1] - alarms[:,0])\n",
      "#     print time_frame / np.timedelta64(1,\"D\"), alarm_time / np.timedelta64(1,\"D\")\n",
      "    return alarm_time / time_frame\n",
      "\n",
      "% time \n",
      "print alarm_fraction(event_times, alarms)\n",
      "\n",
      "# print event_times[0,0]\n",
      "# print event_times[-1,0]\n",
      "# print (validation[\"datetime\"].values[-1] - validation[\"datetime\"].values[0])\n",
      "# print (validation.iloc[-1][\"datetime\"] - validation.iloc[0][\"datetime\"]).total_seconds()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 3 \u00b5s, sys: 0 ns, total: 3 \u00b5s\n",
        "Wall time: 6.91 \u00b5s\n",
        "0.00279148746549\n"
       ]
      }
     ],
     "prompt_number": 231
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Returns the number of correct predictions.\n",
      "Assumes alarm for event i starts before event i if a previous alarm predicted event i.\n",
      "\"\"\"\n",
      "def prediction_positives(event_times, alarms):\n",
      "    num_events = event_times.shape[1]\n",
      "    deltas = event_times > alarms[:,0]\n",
      "    return np.sum(deltas)\n",
      "    \n",
      "% time\n",
      "print prediction_positives(event_times, alarms)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 3 \u00b5s, sys: 0 ns, total: 3 \u00b5s\n",
        "Wall time: 6.34 ms\n",
        "12\n"
       ]
      }
     ],
     "prompt_number": 233
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}